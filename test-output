============================= test session starts =============================
platform win32 -- Python 3.13.0, pytest-8.4.1, pluggy-1.6.0 -- C:\Users\User\product\cmdrdata-openai\.venv\Scripts\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\User\product\cmdrdata-openai
configfile: pyproject.toml
testpaths: tests
plugins: anyio-4.9.0, asyncio-1.0.0, cov-6.2.1, mock-3.14.1
asyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 293 items

tests/test_async_client.py::TestAsyncTrackedOpenAI::test_initialization_success PASSED [  0%]
tests/test_async_client.py::TestAsyncTrackedOpenAI::test_initialization_missing_tracker_key PASSED [  0%]
tests/test_async_client.py::TestAsyncTrackedOpenAI::test_initialization_custom_endpoint PASSED [  1%]
tests/test_async_client.py::TestAsyncTrackedOpenAI::test_get_openai_client PASSED [  1%]
tests/test_async_client.py::TestAsyncTrackedOpenAI::test_get_tracker PASSED [  1%]
tests/test_async_client.py::TestAsyncTrackedOpenAI::test_attribute_delegation PASSED [  2%]
tests/test_async_client.py::TestAsyncTrackedChatCompletions::test_create_with_tracking_success PASSED [  2%]
tests/test_async_client.py::TestAsyncTrackedChatCompletions::test_create_without_tracking PASSED [  2%]
tests/test_async_client.py::TestAsyncTrackedChatCompletions::test_create_no_customer_id PASSED [  3%]
tests/test_async_client.py::TestAsyncTrackedChatCompletions::test_create_no_usage_data PASSED [  3%]
tests/test_async_client.py::TestAsyncTrackedCompletions::test_create_with_tracking_success PASSED [  3%]
tests/test_async_client.py::TestAsyncTrackedChat::test_initialization PASSED [  4%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_api_key_validation_openai PASSED [  4%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_api_key_validation_cmdrdata PASSED [  4%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_api_key_validation_invalid PASSED [  5%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_input_sanitizer_basic PASSED [  5%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_input_sanitizer_removes_null_bytes PASSED [  5%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_retry_config_creation PASSED [  6%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_circuit_breaker_creation PASSED [  6%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_lru_cache_basic PASSED [  6%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_api_key_sanitization_for_logging PASSED [  7%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_url_validation_success PASSED [  7%]
tests/test_basic_functionality.py::TestBasicFunctionality::test_url_validation_failure PASSED [  7%]
tests/test_client.py::TestTrackedOpenAI::test_initialization_success PASSED [  8%]
tests/test_client.py::TestTrackedOpenAI::test_initialization_missing_tracker_key PASSED [  8%]
tests/test_client.py::TestTrackedOpenAI::test_initialization_invalid_api_key PASSED [  8%]
tests/test_client.py::TestTrackedOpenAI::test_initialization_custom_endpoint PASSED [  9%]
tests/test_client.py::TestTrackedOpenAI::test_get_openai_client PASSED   [  9%]
tests/test_client.py::TestTrackedOpenAI::test_get_tracker PASSED         [  9%]
tests/test_client.py::TestTrackedOpenAI::test_compatibility_check_warning PASSED [ 10%]
tests/test_client.py::TestTrackedOpenAI::test_check_compatibility_method PASSED [ 10%]
tests/test_client.py::TestTrackedOpenAI::test_check_compatibility_raise_on_incompatible PASSED [ 10%]
tests/test_client.py::TestTrackedOpenAI::test_get_compatibility_info_method PASSED [ 11%]
tests/test_client.py::TestTrackedOpenAIIntegration::test_proxy_method_delegation PASSED [ 11%]
tests/test_client.py::TestTrackedOpenAIIntegration::test_tracked_method_with_usage_tracking PASSED [ 11%]
tests/test_client.py::TestTrackedOpenAIIntegration::test_environment_variable_initialization PASSED [ 12%]
tests/test_context.py::test_basic_context_operations PASSED              [ 12%]
tests/test_context.py::test_context_manager PASSED                       [ 12%]
tests/test_context.py::test_effective_customer_id_priority PASSED        [ 13%]
tests/test_context.py::test_nested_context_managers PASSED               [ 13%]
tests/test_context.py::test_context_isolation PASSED                     [ 13%]
tests/test_exceptions.py::TestCmdrDataError::test_basic_initialization PASSED [ 14%]
tests/test_exceptions.py::TestCmdrDataError::test_initialization_with_error_code PASSED [ 14%]
tests/test_exceptions.py::TestCmdrDataError::test_initialization_with_details PASSED [ 15%]
tests/test_exceptions.py::TestCmdrDataError::test_initialization_with_all_parameters PASSED [ 15%]
tests/test_exceptions.py::TestCmdrDataError::test_details_default_value PASSED [ 15%]
tests/test_exceptions.py::TestSpecificExceptions::test_configuration_error_inheritance PASSED [ 16%]
tests/test_exceptions.py::TestSpecificExceptions::test_authentication_error_inheritance PASSED [ 16%]
tests/test_exceptions.py::TestSpecificExceptions::test_validation_error_inheritance PASSED [ 16%]
tests/test_exceptions.py::TestSpecificExceptions::test_rate_limit_error_inheritance PASSED [ 17%]
tests/test_exceptions.py::TestSpecificExceptions::test_tracking_error_inheritance PASSED [ 17%]
tests/test_exceptions.py::TestSpecificExceptions::test_network_error_inheritance PASSED [ 17%]
tests/test_exceptions.py::TestSpecificExceptions::test_timeout_error_inheritance PASSED [ 18%]
tests/test_exceptions.py::TestSpecificExceptions::test_retry_exhausted_error_inheritance PASSED [ 18%]
tests/test_exceptions.py::TestSpecificExceptions::test_circuit_breaker_error_inheritance PASSED [ 18%]
tests/test_exceptions.py::TestSpecificExceptions::test_security_error_inheritance PASSED [ 19%]
tests/test_exceptions.py::TestSpecificExceptions::test_compatibility_error_inheritance PASSED [ 19%]
tests/test_exceptions.py::TestExceptionUsage::test_validation_error_with_field_details PASSED [ 19%]
tests/test_exceptions.py::TestExceptionUsage::test_network_error_with_retry_details PASSED [ 20%]
tests/test_exceptions.py::TestExceptionUsage::test_rate_limit_error_with_timing_details PASSED [ 20%]
tests/test_exceptions.py::TestExceptionUsage::test_authentication_error_with_key_details PASSED [ 20%]
tests/test_exceptions.py::TestExceptionUsage::test_circuit_breaker_error_with_state_details PASSED [ 21%]
tests/test_exceptions.py::TestExceptionUsage::test_retry_exhausted_error_with_attempt_details PASSED [ 21%]
tests/test_exceptions.py::TestExceptionChaining::test_exception_can_be_raised_and_caught PASSED [ 21%]
tests/test_exceptions.py::TestExceptionChaining::test_exception_chaining_with_cause PASSED [ 22%]
tests/test_exceptions.py::TestExceptionChaining::test_multiple_exception_types_in_try_except PASSED [ 22%]
tests/test_exceptions.py::TestExceptionChaining::test_exception_hierarchy_catching PASSED [ 22%]
tests/test_logging_config.py::TestStructuredFormatter::test_basic_log_formatting PASSED [ 23%]
tests/test_logging_config.py::TestStructuredFormatter::test_log_formatting_with_custom_fields PASSED [ 23%]
tests/test_logging_config.py::TestStructuredFormatter::test_log_formatting_with_extra_fields PASSED [ 23%]
tests/test_logging_config.py::TestStructuredFormatter::test_log_formatting_with_exception PASSED [ 24%]
tests/test_logging_config.py::TestSecurityFormatter::test_api_key_sanitization PASSED [ 24%]
tests/test_logging_config.py::TestSecurityFormatter::test_no_sanitization_for_safe_content PASSED [ 24%]
tests/test_logging_config.py::TestSecurityFormatter::test_multiple_sensitive_patterns PASSED [ 25%]
tests/test_logging_config.py::TestLoggingConfig::test_default_configuration PASSED [ 25%]
tests/test_logging_config.py::TestLoggingConfig::test_custom_log_level PASSED [ 25%]
tests/test_logging_config.py::TestLoggingConfig::test_structured_format PASSED [ 26%]
tests/test_logging_config.py::TestLoggingConfig::test_standard_format PASSED [ 26%]
tests/test_logging_config.py::TestLoggingConfig::test_file_logging FAILED [ 26%]
tests/test_logging_config.py::TestLoggingConfig::test_console_logging_disabled PASSED [ 27%]
tests/test_logging_config.py::TestLoggingConfig::test_security_mode_enabled PASSED [ 27%]
tests/test_logging_config.py::TestLoggingConfig::test_invalid_log_file_path FAILED [ 27%]
tests/test_logging_config.py::TestRequestLogger::test_request_logger_context PASSED [ 28%]
tests/test_logging_config.py::TestRequestLogger::test_request_logger_cleanup PASSED [ 28%]
tests/test_logging_config.py::TestLogPerformanceDecorator::test_log_performance_success PASSED [ 29%]
tests/test_logging_config.py::TestLogPerformanceDecorator::test_log_performance_error PASSED [ 29%]
tests/test_logging_config.py::TestUtilityFunctions::test_get_logger PASSED [ 29%]
tests/test_logging_config.py::TestUtilityFunctions::test_configure_logging PASSED [ 30%]
tests/test_logging_config.py::TestUtilityFunctions::test_default_logging_config_values FAILED [ 30%]
tests/test_performance.py::TestCacheEntry::test_cache_entry_creation PASSED [ 30%]
tests/test_performance.py::TestCacheEntry::test_cache_entry_is_expired PASSED [ 31%]
tests/test_performance.py::TestCacheEntry::test_cache_entry_touch PASSED [ 31%]
tests/test_performance.py::TestLRUCache::test_lru_cache_basic_operations PASSED [ 31%]
tests/test_performance.py::TestLRUCache::test_lru_cache_eviction PASSED  [ 32%]
tests/test_performance.py::TestLRUCache::test_lru_cache_ttl PASSED       [ 32%]
tests/test_performance.py::TestLRUCache::test_lru_cache_custom_ttl PASSED [ 32%]
tests/test_performance.py::TestLRUCache::test_lru_cache_clear PASSED     [ 33%]
tests/test_performance.py::TestLRUCache::test_lru_cache_stats PASSED     [ 33%]
tests/test_performance.py::TestLRUCache::test_lru_cache_thread_safety PASSED [ 33%]
tests/test_performance.py::TestConnectionPool::test_connection_pool_get_return PASSED [ 34%]
tests/test_performance.py::TestConnectionPool::test_connection_pool_max_keepalive PASSED [ 34%]
tests/test_performance.py::TestConnectionPool::test_connection_pool_clear PASSED [ 34%]
tests/test_performance.py::TestRequestBatcher::test_request_batcher_basic PASSED [ 35%]
tests/test_performance.py::TestRequestBatcher::test_request_batcher_batch_size_trigger PASSED [ 35%]
tests/test_performance.py::TestRequestBatcher::test_request_batcher_error_handling PASSED [ 35%]
tests/test_performance.py::TestRateLimiter::test_rate_limiter_token_bucket PASSED [ 36%]
tests/test_performance.py::TestRateLimiter::test_rate_limiter_token_replenishment PASSED [ 36%]
tests/test_performance.py::TestRateLimiter::test_rate_limiter_multiple_tokens PASSED [ 36%]
tests/test_performance.py::TestRateLimiter::test_rate_limiter_async_acquire PASSED [ 37%]
tests/test_performance.py::TestPerformanceMonitor::test_performance_monitor_metrics PASSED [ 37%]
tests/test_performance.py::TestPerformanceMonitor::test_performance_monitor_counters PASSED [ 37%]
tests/test_performance.py::TestPerformanceMonitor::test_performance_monitor_window_size PASSED [ 38%]
tests/test_performance.py::TestPerformanceDecorators::test_cached_decorator PASSED [ 38%]
tests/test_performance.py::TestPerformanceDecorators::test_timed_decorator PASSED [ 38%]
tests/test_performance.py::TestPerformanceDecorators::test_performance_context PASSED [ 39%]
tests/test_performance.py::TestPerformanceUtilities::test_get_cache_stats PASSED [ 39%]
tests/test_performance.py::TestPerformanceUtilities::test_clear_cache PASSED [ 39%]
tests/test_performance.py::TestPerformanceUtilities::test_configure_performance PASSED [ 40%]
tests/test_proxy.py::TestTrackedProxy::test_proxy_initialization PASSED  [ 40%]
tests/test_proxy.py::TestTrackedProxy::test_getattr_simple_attribute PASSED [ 40%]
tests/test_proxy.py::TestTrackedProxy::test_getattr_tracked_method PASSED [ 41%]
tests/test_proxy.py::TestTrackedProxy::test_getattr_nested_attributes PASSED [ 41%]
tests/test_proxy.py::TestTrackedProxy::test_getattr_nonexistent_attribute FAILED [ 41%]
tests/test_proxy.py::TestTrackedProxy::test_setattr_client_attribute PASSED [ 42%]
tests/test_proxy.py::TestTrackedProxy::test_setattr_private_attribute FAILED [ 42%]
tests/test_proxy.py::TestTrackedProxy::test_dir_method PASSED            [ 43%]
tests/test_proxy.py::TestTrackedProxy::test_wrap_method_basic PASSED     [ 43%]
tests/test_proxy.py::TestTrackedProxy::test_wrap_method_with_tracking_parameters PASSED [ 43%]
tests/test_proxy.py::TestTrackedProxy::test_wrap_method_tracking_disabled PASSED [ 44%]
tests/test_proxy.py::TestTrackedProxy::test_wrap_method_preserves_signature PASSED [ 44%]
tests/test_proxy.py::TestTrackedProxy::test_wrap_method_exception_handling PASSED [ 44%]
tests/test_proxy.py::TestTrackedProxy::test_wrap_method_tracker_exception_handling PASSED [ 45%]
tests/test_proxy.py::TestTrackedProxy::test_repr_method PASSED           [ 45%]
tests/test_proxy.py::TestTrackingFunctions::test_track_chat_completion_success PASSED [ 45%]
tests/test_proxy.py::TestTrackingFunctions::test_track_chat_completion_no_customer_id PASSED [ 46%]
tests/test_proxy.py::TestTrackingFunctions::test_track_chat_completion_no_usage_data PASSED [ 46%]
tests/test_proxy.py::TestTrackingFunctions::test_track_chat_completion_exception_handling PASSED [ 46%]
tests/test_proxy.py::TestTrackingFunctions::test_track_completion_success PASSED [ 47%]
tests/test_proxy.py::TestOpenAITrackMethods::test_openai_track_methods_configuration PASSED [ 47%]
tests/test_retry.py::TestRetryConfig::test_retry_config_initialization_defaults PASSED [ 47%]
tests/test_retry.py::TestRetryConfig::test_retry_config_initialization_custom PASSED [ 48%]
tests/test_retry.py::TestRetryConfig::test_calculate_delay_fixed_interval PASSED [ 48%]
tests/test_retry.py::TestRetryConfig::test_calculate_delay_linear_backoff PASSED [ 48%]
tests/test_retry.py::TestRetryConfig::test_calculate_delay_exponential_backoff PASSED [ 49%]
tests/test_retry.py::TestRetryConfig::test_calculate_delay_max_delay_limit PASSED [ 49%]
tests/test_retry.py::TestRetryConfig::test_calculate_delay_with_jitter PASSED [ 49%]
tests/test_retry.py::TestRetryConfig::test_calculate_delay_jitter_policy PASSED [ 50%]
tests/test_retry.py::TestRetryConfig::test_should_retry_with_retryable_exceptions PASSED [ 50%]
tests/test_retry.py::TestRetryConfig::test_should_retry_with_exception_hierarchy PASSED [ 50%]
tests/test_retry.py::TestCircuitBreaker::test_circuit_breaker_initialization PASSED [ 51%]
tests/test_retry.py::TestCircuitBreaker::test_circuit_breaker_successful_execution PASSED [ 51%]
tests/test_retry.py::TestCircuitBreaker::test_circuit_breaker_failure_counting PASSED [ 51%]
tests/test_retry.py::TestCircuitBreaker::test_circuit_breaker_open_state_rejection PASSED [ 52%]
tests/test_retry.py::TestCircuitBreaker::test_circuit_breaker_half_open_recovery PASSED [ 52%]
tests/test_retry.py::TestCircuitBreaker::test_circuit_breaker_half_open_failure PASSED [ 52%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_async_success PASSED [ 53%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_async_eventual_success PASSED [ 53%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_async_max_attempts_exceeded PASSED [ 53%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_async_non_retryable_exception PASSED [ 54%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_sync_success PASSED [ 54%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_sync_eventual_success PASSED [ 54%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_sync_max_attempts_exceeded PASSED [ 55%]
tests/test_retry.py::TestRetryDecorator::test_retry_decorator_with_circuit_breaker PASSED [ 55%]
tests/test_retry.py::TestDefaultConfigurations::test_default_retry_config PASSED [ 55%]
tests/test_retry.py::TestDefaultConfigurations::test_aggressive_retry_config PASSED [ 56%]
tests/test_retry.py::TestDefaultConfigurations::test_conservative_retry_config PASSED [ 56%]
tests/test_retry.py::TestDefaultConfigurations::test_default_circuit_breaker PASSED [ 56%]
tests/test_security.py::TestAPIKeyManager::test_validate_openai_api_key_success PASSED [ 57%]
tests/test_security.py::TestAPIKeyManager::test_validate_cmdrdata_api_key_success PASSED [ 57%]
tests/test_security.py::TestAPIKeyManager::test_validate_api_key_empty_string PASSED [ 58%]
tests/test_security.py::TestAPIKeyManager::test_validate_api_key_none PASSED [ 58%]
tests/test_security.py::TestAPIKeyManager::test_validate_api_key_too_short PASSED [ 58%]
tests/test_security.py::TestAPIKeyManager::test_validate_api_key_too_long PASSED [ 59%]
tests/test_security.py::TestAPIKeyManager::test_validate_api_key_suspicious_patterns PASSED [ 59%]
tests/test_security.py::TestAPIKeyManager::test_validate_api_key_invalid_format PASSED [ 59%]
tests/test_security.py::TestAPIKeyManager::test_sanitize_api_key_for_logging PASSED [ 60%]
tests/test_security.py::TestAPIKeyManager::test_generate_tracking_key PASSED [ 60%]
tests/test_security.py::TestAPIKeyManager::test_hash_and_verify_api_key PASSED [ 60%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_basic PASSED [ 61%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_remove_suspicious PASSED [ 61%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_strict_mode PASSED [ 61%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_length_limit PASSED [ 62%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_strict_length_limit PASSED [ 62%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_pattern_validation PASSED [ 62%]
tests/test_security.py::TestInputSanitizer::test_sanitize_string_non_string_input PASSED [ 63%]
tests/test_security.py::TestInputSanitizer::test_validate_url_valid PASSED [ 63%]
tests/test_security.py::TestInputSanitizer::test_validate_url_invalid_scheme PASSED [ 63%]
tests/test_security.py::TestInputSanitizer::test_validate_url_custom_schemes PASSED [ 64%]
tests/test_security.py::TestInputSanitizer::test_validate_url_suspicious_patterns PASSED [ 64%]
tests/test_security.py::TestInputSanitizer::test_validate_url_too_long PASSED [ 64%]
tests/test_security.py::TestInputSanitizer::test_validate_url_private_ip_production PASSED [ 65%]
tests/test_security.py::TestInputSanitizer::test_sanitize_metadata_valid PASSED [ 65%]
tests/test_security.py::TestInputSanitizer::test_sanitize_metadata_invalid_type PASSED [ 65%]
tests/test_security.py::TestInputSanitizer::test_sanitize_metadata_non_string_keys PASSED [ 66%]
tests/test_security.py::TestInputSanitizer::test_sanitize_metadata_too_large PASSED [ 66%]
tests/test_security.py::TestInputSanitizer::test_sanitize_metadata_suspicious_content PASSED [ 66%]
tests/test_security.py::TestRateLimiter::test_rate_limiter_allows_requests PASSED [ 67%]
tests/test_security.py::TestRateLimiter::test_rate_limiter_different_identifiers PASSED [ 67%]
tests/test_security.py::TestRateLimiter::test_rate_limiter_window_reset PASSED [ 67%]
tests/test_security.py::TestRateLimiter::test_rate_limiter_get_reset_time PASSED [ 68%]
tests/test_security.py::TestSecurityDecorators::test_require_valid_api_key_decorator PASSED [ 68%]
tests/test_security.py::TestSecurityDecorators::test_rate_limited_decorator PASSED [ 68%]
tests/test_security.py::TestSecurityUtilities::test_secure_compare PASSED [ 69%]
tests/test_security.py::TestSecurityUtilities::test_generate_secure_token PASSED [ 69%]
tests/test_security.py::TestSecurityUtilities::test_validate_request_signature PASSED [ 69%]
tests/test_security.py::TestSecurityConfig::test_security_config_defaults PASSED [ 70%]
tests/test_security.py::TestSecurityConfig::test_security_config_environment_override PASSED [ 70%]
tests/test_tracker.py::TestUsageTracker::test_initialization_success PASSED [ 70%]
tests/test_tracker.py::TestUsageTracker::test_initialization_missing_api_key FAILED [ 71%]
tests/test_tracker.py::TestUsageTracker::test_initialization_invalid_api_key_format FAILED [ 71%]
tests/test_tracker.py::TestUsageTracker::test_initialization_missing_endpoint FAILED [ 72%]
tests/test_tracker.py::TestUsageTracker::test_initialization_invalid_endpoint FAILED [ 72%]
tests/test_tracker.py::TestUsageTracker::test_initialization_invalid_timeout FAILED [ 72%]
tests/test_tracker.py::TestUsageTracker::test_initialization_default_values PASSED [ 73%]
tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_success FAILED [ 73%]
tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_missing_customer_id FAILED [ 73%]
tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_invalid_tokens FAILED [ 74%]
tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_invalid_metadata FAILED [ 74%]
tests/test_tracker.py::TestUsageTracker::test_sanitize_tracking_data FAILED [ 74%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_success_httpx FAILED [ 75%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_success_requests FAILED [ 75%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_rate_limited FAILED [ 75%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_server_error FAILED [ 76%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_client_error FAILED [ 76%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_network_error FAILED [ 76%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_success FAILED [ 77%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_validation_error FAILED [ 77%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_async_success PASSED [ 77%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_async_fallback PASSED [ 78%]
tests/test_tracker.py::TestUsageTracker::test_track_usage_background PASSED [ 78%]
tests/test_tracker.py::TestUsageTracker::test_get_health_status FAILED   [ 78%]
tests/test_tracker.py::TestUsageTracker::test_cleanup_on_deletion PASSED [ 79%]
tests/test_tracker.py::TestUsageTrackerIntegration::test_full_tracking_flow_success FAILED [ 79%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_openai_success PASSED [ 79%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_cmdrdata_success PASSED [ 80%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_generic_success PASSED [ 80%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_empty_string PASSED [ 80%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_none PASSED [ 81%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_suspicious_patterns PASSED [ 81%]
tests/test_validation.py::TestAPIKeyManager::test_validate_api_key_invalid_format PASSED [ 81%]
tests/test_validation.py::TestAPIKeyManager::test_validate_customer_id_success PASSED [ 82%]
tests/test_validation.py::TestAPIKeyManager::test_validate_customer_id_empty_string PASSED [ 82%]
tests/test_validation.py::TestAPIKeyManager::test_validate_customer_id_too_long PASSED [ 82%]
tests/test_validation.py::TestAPIKeyManager::test_validate_customer_id_suspicious_patterns PASSED [ 83%]
tests/test_validation.py::TestAPIKeyManager::test_validate_customer_id_invalid_characters PASSED [ 83%]
tests/test_validation.py::TestAPIKeyManager::test_validate_url_success PASSED [ 83%]
tests/test_validation.py::TestAPIKeyManager::test_validate_url_empty_string PASSED [ 84%]
tests/test_validation.py::TestAPIKeyManager::test_validate_url_invalid_scheme FAILED [ 84%]
tests/test_validation.py::TestAPIKeyManager::test_validate_url_suspicious_patterns PASSED [ 84%]
tests/test_validation.py::TestAPIKeyManager::test_validate_url_malformed FAILED [ 85%]
tests/test_validation.py::TestAPIKeyManager::test_validate_timeout_success PASSED [ 85%]
tests/test_validation.py::TestAPIKeyManager::test_validate_timeout_invalid_type PASSED [ 86%]
tests/test_validation.py::TestAPIKeyManager::test_validate_timeout_negative PASSED [ 86%]
tests/test_validation.py::TestAPIKeyManager::test_validate_timeout_too_large PASSED [ 86%]
tests/test_validation.py::TestAPIKeyManager::test_validate_model_name_success PASSED [ 87%]
tests/test_validation.py::TestAPIKeyManager::test_validate_model_name_empty_string PASSED [ 87%]
tests/test_validation.py::TestAPIKeyManager::test_validate_model_name_suspicious_patterns PASSED [ 87%]
tests/test_validation.py::TestAPIKeyManager::test_validate_model_name_invalid_characters PASSED [ 88%]
tests/test_validation.py::TestAPIKeyManager::test_validate_token_count_success PASSED [ 88%]
tests/test_validation.py::TestAPIKeyManager::test_validate_token_count_invalid_type PASSED [ 88%]
tests/test_validation.py::TestAPIKeyManager::test_validate_token_count_negative PASSED [ 89%]
tests/test_validation.py::TestAPIKeyManager::test_validate_token_count_too_large PASSED [ 89%]
tests/test_validation.py::TestAPIKeyManager::test_validate_metadata_success PASSED [ 89%]
tests/test_validation.py::TestAPIKeyManager::test_validate_metadata_invalid_type PASSED [ 90%]
tests/test_validation.py::TestAPIKeyManager::test_validate_metadata_too_large PASSED [ 90%]
tests/test_validation.py::TestAPIKeyManager::test_validate_metadata_non_string_keys PASSED [ 90%]
tests/test_validation.py::TestAPIKeyManager::test_validate_metadata_suspicious_keys PASSED [ 91%]
tests/test_validation.py::TestAPIKeyManager::test_validate_metadata_suspicious_values PASSED [ 91%]
tests/test_validation.py::TestAPIKeyManager::test_sanitize_string_basic PASSED [ 91%]
tests/test_validation.py::TestAPIKeyManager::test_sanitize_string_with_null_bytes PASSED [ 92%]
tests/test_validation.py::TestAPIKeyManager::test_sanitize_string_truncation PASSED [ 92%]
tests/test_validation.py::TestAPIKeyManager::test_sanitize_string_non_string_input PASSED [ 92%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_success PASSED [ 93%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_empty_list PASSED [ 93%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_invalid_type PASSED [ 93%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_invalid_message_type PASSED [ 94%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_missing_role PASSED [ 94%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_invalid_role PASSED [ 94%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_missing_content PASSED [ 95%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_non_string_content PASSED [ 95%]
tests/test_validation.py::TestAPIKeyManager::test_validate_chat_messages_suspicious_content PASSED [ 95%]
tests/test_validation.py::TestValidateInputDecorator::test_validate_input_decorator_success PASSED [ 96%]
tests/test_validation.py::TestValidateInputDecorator::test_validate_input_decorator_validation_error PASSED [ 96%]
tests/test_validation.py::TestValidateInputDecorator::test_validate_input_decorator_security_error PASSED [ 96%]
tests/test_validation.py::TestValidateInputDecorator::test_validate_input_decorator_unexpected_error PASSED [ 97%]
tests/test_version_compat.py::test_compatibility_info_structure PASSED   [ 97%]
tests/test_version_compat.py::test_openai_version_detection FAILED       [ 97%]
tests/test_version_compat.py::test_unsupported_openai_version FAILED     [ 98%]
tests/test_version_compat.py::test_missing_openai FAILED                 [ 98%]
tests/test_version_compat.py::test_check_compatibility_function PASSED   [ 98%]
tests/test_version_compat.py::test_version_warnings FAILED               [ 99%]
tests/test_version_compat.py::test_python_version_support FAILED         [ 99%]
tests/test_version_compat.py::test_compatibility_with_fallback_version FAILED [100%]

================================== FAILURES ===================================
_____________________ TestLoggingConfig.test_file_logging _____________________

self = <tests.test_logging_config.TestLoggingConfig object at 0x000001C694C795B0>

    def test_file_logging(self):
        """Test file logging configuration"""
        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            temp_path = temp_file.name
    
        try:
            config = LoggingConfig({
                'log_file': temp_path,
                'console_logging': False
            })
    
            logger = logging.getLogger('cmdrdata_openai')
    
            # Should have file handler
            file_handlers = [h for h in logger.handlers if hasattr(h, 'baseFilename')]
            assert len(file_handlers) >= 1
    
            # Test logging to file
            logger.info("Test file logging")
    
            # Force flush
            for handler in file_handlers:
                handler.flush()
    
            # Check file content
            with open(temp_path, 'r') as f:
                content = f.read()
                assert "Test file logging" in content
    
        finally:
            # Clean up
            if os.path.exists(temp_path):
>               os.unlink(temp_path)
E               PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\User\\AppData\\Local\\Temp\\tmpzys8mihh'

tests\test_logging_config.py:324: PermissionError
---------------------------- Captured stderr call -----------------------------
INFO:cmdrdata_openai:Test file logging
------------------------------ Captured log call ------------------------------
INFO     cmdrdata_openai:test_logging_config.py:310 Test file logging
________________ TestLoggingConfig.test_invalid_log_file_path _________________

self = <tests.test_logging_config.TestLoggingConfig object at 0x000001C694BE6350>

    def test_invalid_log_file_path(self):
        """Test handling of invalid log file path"""
>       with patch('cmdrdata_openai.logging_config.logger') as mock_logger:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_logging_config.py:354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694F38050>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'cmdrdata_openai.logging_config' from 'C:\\Users\\User\\product\\cmdrdata-openai\\cmdrdata_openai\\logging_config.py'> does not have the attribute 'logger'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
___________ TestUtilityFunctions.test_default_logging_config_values ___________

self = <tests.test_logging_config.TestUtilityFunctions object at 0x000001C694C84FC0>

    def test_default_logging_config_values(self):
        """Test DEFAULT_LOGGING_CONFIG contains expected values"""
>       config = DEFAULT_LOGGING_CONFIG
                 ^^^^^^^^^^^^^^^^^^^^^^
E       UnboundLocalError: cannot access local variable 'DEFAULT_LOGGING_CONFIG' where it is not associated with a value

tests\test_logging_config.py:492: UnboundLocalError
_____________ TestTrackedProxy.test_getattr_nonexistent_attribute _____________

self = <tests.test_proxy.TestTrackedProxy object at 0x000001C694CC7770>

    def test_getattr_nonexistent_attribute(self):
        """Test __getattr__ for non-existent attributes"""
        proxy = TrackedProxy(
            client=self.mock_client,
            tracker=self.mock_tracker,
            track_methods={}
        )
    
>       with pytest.raises(AttributeError, match="'Mock' object has no attribute 'nonexistent'"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'AttributeError'>

tests\test_proxy.py:113: Failed
_______________ TestTrackedProxy.test_setattr_private_attribute _______________

self = <tests.test_proxy.TestTrackedProxy object at 0x000001C694CB47C0>

    def test_setattr_private_attribute(self):
        """Test __setattr__ for private attributes"""
        proxy = TrackedProxy(
            client=self.mock_client,
            tracker=self.mock_tracker,
            track_methods={}
        )
    
        proxy._private_attr = "private_value"
    
        # Should set on the proxy itself
        assert proxy._private_attr == "private_value"
>       assert not hasattr(self.mock_client, '_private_attr')
E       AssertionError: assert not True
E        +  where True = hasattr(<Mock id='1952413922848'>, '_private_attr')
E        +    where <Mock id='1952413922848'> = <tests.test_proxy.TestTrackedProxy object at 0x000001C694CB47C0>.mock_client

tests\test_proxy.py:141: AssertionError
____________ TestUsageTracker.test_initialization_missing_api_key _____________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D39090>

    def test_initialization_missing_api_key(self):
        """Test initialization failure when API key is missing"""
>       with pytest.raises(ValidationError, match="API key is required"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'cmdrdata_openai.exceptions.ValidationError'>

tests\test_tracker.py:48: Failed
_________ TestUsageTracker.test_initialization_invalid_api_key_format _________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694C87490>

    def test_initialization_invalid_api_key_format(self):
        """Test initialization with invalid API key format"""
>       with pytest.raises(ValidationError, match="Invalid API key"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'cmdrdata_openai.exceptions.ValidationError'>

tests\test_tracker.py:53: Failed
____________ TestUsageTracker.test_initialization_missing_endpoint ____________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694C875C0>

    def test_initialization_missing_endpoint(self):
        """Test initialization failure when endpoint is missing"""
>       with pytest.raises(ValidationError, match="Endpoint is required"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'cmdrdata_openai.exceptions.ValidationError'>

tests\test_tracker.py:58: Failed
____________ TestUsageTracker.test_initialization_invalid_endpoint ____________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D64170>

    def test_initialization_invalid_endpoint(self):
        """Test initialization with invalid endpoint URL"""
>       with pytest.raises(ValidationError, match="Invalid endpoint URL"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'cmdrdata_openai.exceptions.ValidationError'>

tests\test_tracker.py:63: Failed
____________ TestUsageTracker.test_initialization_invalid_timeout _____________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694CB58C0>

    def test_initialization_invalid_timeout(self):
        """Test initialization with invalid timeout"""
>       with pytest.raises(ValidationError, match="Invalid timeout"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'cmdrdata_openai.exceptions.ValidationError'>

tests\test_tracker.py:68: Failed
___________ TestUsageTracker.test_validate_tracking_inputs_success ____________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D5C150>

    def test_validate_tracking_inputs_success(self):
        """Test successful input validation"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        # Should not raise any exceptions
>       tracker._validate_tracking_inputs(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            customer_id=self.customer_id,
            model=self.model,
            input_tokens=self.input_tokens,
            output_tokens=self.output_tokens,
            provider="openai",
            metadata={"test": "value"}
        )
E       AttributeError: 'UsageTracker' object has no attribute '_validate_tracking_inputs'

tests\test_tracker.py:84: AttributeError
_____ TestUsageTracker.test_validate_tracking_inputs_missing_customer_id ______

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D5C250>

    def test_validate_tracking_inputs_missing_customer_id(self):
        """Test input validation with missing customer ID"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        with pytest.raises(ValidationError, match="Customer ID is required"):
>           tracker._validate_tracking_inputs(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                customer_id="",
                model=self.model,
                input_tokens=self.input_tokens,
                output_tokens=self.output_tokens,
                provider="openai",
                metadata=None
            )
E           AttributeError: 'UsageTracker' object has no attribute '_validate_tracking_inputs'

tests\test_tracker.py:98: AttributeError
________ TestUsageTracker.test_validate_tracking_inputs_invalid_tokens ________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D287D0>

    def test_validate_tracking_inputs_invalid_tokens(self):
        """Test input validation with invalid token counts"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        with pytest.raises(ValidationError, match="Token count cannot be negative"):
>           tracker._validate_tracking_inputs(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                customer_id=self.customer_id,
                model=self.model,
                input_tokens=-1,
                output_tokens=self.output_tokens,
                provider="openai",
                metadata=None
            )
E           AttributeError: 'UsageTracker' object has no attribute '_validate_tracking_inputs'

tests\test_tracker.py:112: AttributeError
_______ TestUsageTracker.test_validate_tracking_inputs_invalid_metadata _______

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D289B0>

    def test_validate_tracking_inputs_invalid_metadata(self):
        """Test input validation with invalid metadata"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        with pytest.raises(ValidationError, match="Metadata must be a dictionary"):
>           tracker._validate_tracking_inputs(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                customer_id=self.customer_id,
                model=self.model,
                input_tokens=self.input_tokens,
                output_tokens=self.output_tokens,
                provider="openai",
                metadata="invalid"
            )
E           AttributeError: 'UsageTracker' object has no attribute '_validate_tracking_inputs'

tests\test_tracker.py:126: AttributeError
________________ TestUsageTracker.test_sanitize_tracking_data _________________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D41630>

    def test_sanitize_tracking_data(self):
        """Test data sanitization"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        metadata = {"key1": "value1", "key2": 123}
        timestamp = datetime.utcnow()
    
>       sanitized = tracker._sanitize_tracking_data(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            customer_id=self.customer_id,
            model=self.model,
            input_tokens=self.input_tokens,
            output_tokens=self.output_tokens,
            provider="openai",
            metadata=metadata,
            timestamp=timestamp
        )
E       AttributeError: 'UsageTracker' object has no attribute '_sanitize_tracking_data'

tests\test_tracker.py:142: AttributeError
_________ TestUsageTracker.test_track_usage_with_retry_success_httpx __________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D418D0>
mock_httpx = <MagicMock name='httpx' id='1952413917808'>

    @patch('cmdrdata_openai.tracker.httpx')
    def test_track_usage_with_retry_success_httpx(self, mock_httpx):
        """Test successful usage tracking with httpx"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        # Mock httpx client and response
        mock_client = Mock()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_client.post.return_value = mock_response
        mock_httpx.Client.return_value.__enter__.return_value = mock_client
    
        event_data = {
            "customer_id": self.customer_id,
            "model": self.model,
            "input_tokens": self.input_tokens,
            "output_tokens": self.output_tokens,
            "total_tokens": self.input_tokens + self.output_tokens,
            "provider": "openai",
            "metadata": {},
            "timestamp": datetime.utcnow().isoformat(),
            "version": "0.1.0"
        }
    
>       result = tracker._track_usage_with_retry(event_data)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UsageTracker' object has no attribute '_track_usage_with_retry'

tests\test_tracker.py:186: AttributeError
________ TestUsageTracker.test_track_usage_with_retry_success_requests ________

args = (<tests.test_tracker.TestUsageTracker object at 0x000001C694C9AC30>,)
keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1402: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694C9A750>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'cmdrdata_openai.tracker' from 'C:\\Users\\User\\product\\cmdrdata-openai\\cmdrdata_openai\\tracker.py'> does not have the attribute 'requests'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
__________ TestUsageTracker.test_track_usage_with_retry_rate_limited __________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694BED610>
mock_httpx = <MagicMock name='httpx' id='1952412974256'>

    @patch('cmdrdata_openai.tracker.httpx')
    def test_track_usage_with_retry_rate_limited(self, mock_httpx):
        """Test usage tracking with rate limit response"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        # Mock httpx client and rate limit response
        mock_client = Mock()
        mock_response = Mock()
        mock_response.status_code = 429
        mock_client.post.return_value = mock_response
        mock_httpx.Client.return_value.__enter__.return_value = mock_client
    
        event_data = {"test": "data"}
    
        with pytest.raises(NetworkError, match="Rate limited"):
>           tracker._track_usage_with_retry(event_data)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'UsageTracker' object has no attribute '_track_usage_with_retry'

tests\test_tracker.py:243: AttributeError
__________ TestUsageTracker.test_track_usage_with_retry_server_error __________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694BED6D0>
mock_httpx = <MagicMock name='httpx' id='1952412972576'>

    @patch('cmdrdata_openai.tracker.httpx')
    def test_track_usage_with_retry_server_error(self, mock_httpx):
        """Test usage tracking with server error response"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        # Mock httpx client and server error response
        mock_client = Mock()
        mock_response = Mock()
        mock_response.status_code = 500
        mock_response.text = "Internal Server Error"
        mock_client.post.return_value = mock_response
        mock_httpx.Client.return_value.__enter__.return_value = mock_client
    
        event_data = {"test": "data"}
    
        with pytest.raises(NetworkError, match="Server error"):
>           tracker._track_usage_with_retry(event_data)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'UsageTracker' object has no attribute '_track_usage_with_retry'

tests\test_tracker.py:261: AttributeError
__________ TestUsageTracker.test_track_usage_with_retry_client_error __________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694CADDE0>
mock_httpx = <MagicMock name='httpx' id='1952432441056'>

    @patch('cmdrdata_openai.tracker.httpx')
    def test_track_usage_with_retry_client_error(self, mock_httpx):
        """Test usage tracking with client error response"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        # Mock httpx client and client error response
        mock_client = Mock()
        mock_response = Mock()
        mock_response.status_code = 400
        mock_response.text = "Bad Request"
        mock_client.post.return_value = mock_response
        mock_httpx.Client.return_value.__enter__.return_value = mock_client
    
        event_data = {"test": "data"}
    
        with pytest.raises(TrackingError, match="Client error"):
>           tracker._track_usage_with_retry(event_data)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'UsageTracker' object has no attribute '_track_usage_with_retry'

tests\test_tracker.py:279: AttributeError
_________ TestUsageTracker.test_track_usage_with_retry_network_error __________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694CADE90>
mock_httpx = <MagicMock name='httpx' id='1952432448112'>

    @patch('cmdrdata_openai.tracker.httpx')
    def test_track_usage_with_retry_network_error(self, mock_httpx):
        """Test usage tracking with network error"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        # Mock httpx client to raise RequestError
        mock_client = Mock()
        mock_client.post.side_effect = Exception("Connection failed")
        mock_httpx.Client.return_value.__enter__.return_value = mock_client
        mock_httpx.RequestError = Exception
    
        event_data = {"test": "data"}
    
        with pytest.raises(TrackingError, match="Tracking failed"):
>           tracker._track_usage_with_retry(event_data)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'UsageTracker' object has no attribute '_track_usage_with_retry'

tests\test_tracker.py:295: AttributeError
__________________ TestUsageTracker.test_track_usage_success __________________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D30F50>

    def test_track_usage_success(self):
        """Test successful track_usage method"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
>       with patch.object(tracker, '_validate_tracking_inputs') as mock_validate:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_tracker.py:301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694F39640>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <cmdrdata_openai.tracker.UsageTracker object at 0x000001C696071750> does not have the attribute '_validate_tracking_inputs'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
_____________ TestUsageTracker.test_track_usage_validation_error ______________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D32990>

    def test_track_usage_validation_error(self):
        """Test track_usage with validation error"""
        tracker = UsageTracker(api_key=self.valid_api_key)
    
>       with pytest.raises(ValidationError):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'cmdrdata_openai.exceptions.ValidationError'>

tests\test_tracker.py:323: Failed
---------------------------- Captured stderr call -----------------------------
WARNING:cmdrdata_openai.cmdrdata_openai.tracker:Failed to track usage: 401 {"detail":"Invalid API key"}
------------------------------ Captured log call ------------------------------
WARNING  cmdrdata_openai.cmdrdata_openai.tracker:tracker.py:113 Failed to track usage: 401 {"detail":"Invalid API key"}
___________________ TestUsageTracker.test_get_health_status ___________________

self = <tests.test_tracker.TestUsageTracker object at 0x000001C694D135B0>

    def test_get_health_status(self):
        """Test health status method"""
        tracker = UsageTracker(
            api_key=self.valid_api_key,
            endpoint=self.valid_endpoint,
            timeout=10.0,
            max_retries=5
        )
    
>       status = tracker.get_health_status()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UsageTracker' object has no attribute 'get_health_status'

tests\test_tracker.py:399: AttributeError
_________ TestUsageTrackerIntegration.test_full_tracking_flow_success _________

self = <tests.test_tracker.TestUsageTrackerIntegration object at 0x000001C694D391D0>
mock_httpx = <MagicMock name='httpx' id='1952432450128'>

    @patch('cmdrdata_openai.tracker.httpx')
    def test_full_tracking_flow_success(self, mock_httpx):
        """Test complete tracking flow from input to HTTP request"""
        # Mock httpx
        mock_client = Mock()
        mock_response = Mock()
        mock_response.status_code = 200
        mock_client.post.return_value = mock_response
        mock_httpx.Client.return_value.__enter__.return_value = mock_client
    
        tracker = UsageTracker(api_key=self.valid_api_key)
    
        result = tracker.track_usage(
            customer_id=self.customer_id,
            model=self.model,
            input_tokens=self.input_tokens,
            output_tokens=self.output_tokens,
            provider="openai",
            metadata={"test_key": "test_value"},
            timestamp=datetime(2023, 1, 1, 12, 0, 0)
        )
    
        assert result is True
    
        # Verify the HTTP request was made with correct data
        mock_client.post.assert_called_once()
        call_args = mock_client.post.call_args
    
        assert call_args[1]["json"]["customer_id"] == self.customer_id
        assert call_args[1]["json"]["model"] == self.model
        assert call_args[1]["json"]["input_tokens"] == self.input_tokens
        assert call_args[1]["json"]["output_tokens"] == self.output_tokens
>       assert call_args[1]["json"]["total_tokens"] == 25
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'total_tokens'

tests\test_tracker.py:459: KeyError
_____________ TestAPIKeyManager.test_validate_url_invalid_scheme ______________

self = <tests.test_validation.TestAPIKeyManager object at 0x000001C694BEDC10>

    def test_validate_url_invalid_scheme(self):
        """Test URL validation with invalid scheme"""
        with pytest.raises(ValidationError, match="URL must use HTTP or HTTPS protocol"):
>           InputSanitizer.validate_url("ftp://example.com")

tests\test_validation.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'cmdrdata_openai.security.InputSanitizer'>
url = 'ftp://example.com', allowed_schemes = {'http', 'https'}

    @classmethod
    def validate_url(cls, url: str, allowed_schemes: Optional[Set[str]] = None) -> str:
        """
        Validate and sanitize URL
    
        Args:
            url: The URL to validate
            allowed_schemes: Set of allowed URL schemes
    
        Returns:
            Validated URL
    
        Raises:
            ValidationError: If URL is invalid
            SecurityError: If URL is suspicious
        """
        if not url or not isinstance(url, str):
            raise ValidationError("URL must be a non-empty string")
    
        # Check length
        if len(url) > cls.MAX_LENGTHS['url']:
            raise ValidationError(f"URL too long. Maximum length: {cls.MAX_LENGTHS['url']}")
    
        # Parse URL
        try:
            parsed = urlparse(url)
        except Exception as e:
            raise ValidationError(f"Invalid URL format: {e}")
    
        # Check scheme
        if allowed_schemes is None:
            allowed_schemes = {'http', 'https'}
    
        if parsed.scheme not in allowed_schemes:
>           raise ValidationError(f"URL scheme must be one of: {', '.join(allowed_schemes)}")
E           cmdrdata_openai.exceptions.ValidationError: URL scheme must be one of: http, https

cmdrdata_openai\security.py:325: ValidationError

During handling of the above exception, another exception occurred:

self = <tests.test_validation.TestAPIKeyManager object at 0x000001C694BEDC10>

    def test_validate_url_invalid_scheme(self):
        """Test URL validation with invalid scheme"""
>       with pytest.raises(ValidationError, match="URL must use HTTP or HTTPS protocol"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: Regex pattern did not match.
E        Regex: 'URL must use HTTP or HTTPS protocol'
E        Input: 'URL scheme must be one of: http, https'

tests\test_validation.py:135: AssertionError
________________ TestAPIKeyManager.test_validate_url_malformed ________________

self = <tests.test_validation.TestAPIKeyManager object at 0x000001C694CAE0A0>

    def test_validate_url_malformed(self):
        """Test URL validation with malformed URL"""
        with pytest.raises(ValidationError, match="Invalid URL format"):
>           InputSanitizer.validate_url("not a valid url")

tests\test_validation.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'cmdrdata_openai.security.InputSanitizer'>, url = 'not a valid url'
allowed_schemes = {'http', 'https'}

    @classmethod
    def validate_url(cls, url: str, allowed_schemes: Optional[Set[str]] = None) -> str:
        """
        Validate and sanitize URL
    
        Args:
            url: The URL to validate
            allowed_schemes: Set of allowed URL schemes
    
        Returns:
            Validated URL
    
        Raises:
            ValidationError: If URL is invalid
            SecurityError: If URL is suspicious
        """
        if not url or not isinstance(url, str):
            raise ValidationError("URL must be a non-empty string")
    
        # Check length
        if len(url) > cls.MAX_LENGTHS['url']:
            raise ValidationError(f"URL too long. Maximum length: {cls.MAX_LENGTHS['url']}")
    
        # Parse URL
        try:
            parsed = urlparse(url)
        except Exception as e:
            raise ValidationError(f"Invalid URL format: {e}")
    
        # Check scheme
        if allowed_schemes is None:
            allowed_schemes = {'http', 'https'}
    
        if parsed.scheme not in allowed_schemes:
>           raise ValidationError(f"URL scheme must be one of: {', '.join(allowed_schemes)}")
E           cmdrdata_openai.exceptions.ValidationError: URL scheme must be one of: http, https

cmdrdata_openai\security.py:325: ValidationError

During handling of the above exception, another exception occurred:

self = <tests.test_validation.TestAPIKeyManager object at 0x000001C694CAE0A0>

    def test_validate_url_malformed(self):
        """Test URL validation with malformed URL"""
>       with pytest.raises(ValidationError, match="Invalid URL format"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: Regex pattern did not match.
E        Regex: 'Invalid URL format'
E        Input: 'URL scheme must be one of: http, https'

tests\test_validation.py:152: AssertionError
________________________ test_openai_version_detection ________________________

args = (), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1402: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694C9AF70>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'cmdrdata_openai.version_compat' from 'C:\\Users\\User\\product\\cmdrdata-openai\\cmdrdata_openai\\version_compat.py'> does not have the attribute 'openai'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
_______________________ test_unsupported_openai_version _______________________

args = (), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1402: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694C9B040>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'cmdrdata_openai.version_compat' from 'C:\\Users\\User\\product\\cmdrdata-openai\\cmdrdata_openai\\version_compat.py'> does not have the attribute 'openai'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
_____________________________ test_missing_openai _____________________________

args = (), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1402: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694C9B110>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'cmdrdata_openai.version_compat' from 'C:\\Users\\User\\product\\cmdrdata-openai\\cmdrdata_openai\\version_compat.py'> does not have the attribute 'openai'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
____________________________ test_version_warnings ____________________________

args = (), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1402: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1491: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001C694C9B1E0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'cmdrdata_openai.version_compat' from 'C:\\Users\\User\\product\\cmdrdata-openai\\cmdrdata_openai\\version_compat.py'> does not have the attribute 'openai'

..\..\appdata\local\programs\python\python313\Lib\unittest\mock.py:1464: AttributeError
_________________________ test_python_version_support _________________________

    @patch('cmdrdata_openai.version_compat.sys.version_info', (3, 7, 0))
    def test_python_version_support():
        """Test Python version support detection"""
>       info = get_compatibility_info()
               ^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_version_compat.py:84: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
cmdrdata_openai\version_compat.py:134: in get_compatibility_info
    return _version_compat.get_compatibility_info()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <cmdrdata_openai.version_compat.VersionCompatibility object at 0x000001C693D6AE40>

    def get_compatibility_info(self) -> Dict[str, Any]:
        """Get comprehensive compatibility information"""
        return {
            "openai": {
                "installed": self.openai_version,
                "supported": self.is_openai_supported(),
                "min_supported": self.SUPPORTED_OPENAI_VERSIONS["min"],
                "max_supported": self.SUPPORTED_OPENAI_VERSIONS["max"],
                "tested_versions": self.SUPPORTED_OPENAI_VERSIONS["tested"]
            },
            "python": {
>               "version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                              ^^^^^^^^^^^^^^^^^^^^^^
                "supported": sys.version_info >= (3, 8)
            }
        }
E       AttributeError: 'tuple' object has no attribute 'major'

cmdrdata_openai\version_compat.py:109: AttributeError
__________________ test_compatibility_with_fallback_version ___________________

    def test_compatibility_with_fallback_version():
        """Test compatibility checking with fallback version parser"""
        # This tests the fallback when packaging module is not available
        with patch('cmdrdata_openai.version_compat.version', side_effect=ImportError):
            # Should still work with basic version comparison
>           compat = VersionCompatibility()
                     ^^^^^^^^^^^^^^^^^^^^^^

tests\test_version_compat.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
cmdrdata_openai\version_compat.py:38: in __init__
    self._check_openai_version()
cmdrdata_openai\version_compat.py:45: in _check_openai_version
    self._validate_openai_version()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <cmdrdata_openai.version_compat.VersionCompatibility object at 0x000001C694D39E50>

    def _validate_openai_version(self):
        """Validate OpenAI version and show warnings if needed"""
        if not self.openai_version:
            return
    
        current = version.parse(self.openai_version)
        min_version = version.parse(self.SUPPORTED_OPENAI_VERSIONS["min"])
        max_version = version.parse(self.SUPPORTED_OPENAI_VERSIONS["max"])
    
>       if current < min_version:
           ^^^^^^^^^^^^^^^^^^^^^
E       TypeError: '<' not supported between instances of 'MagicMock' and 'MagicMock'

cmdrdata_openai\version_compat.py:62: TypeError
============================== warnings summary ===============================
cmdrdata_openai\version_compat.py:38
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\version_compat.py:38: UserWarning: cmdrdata-openai: OpenAI SDK version 1.93.1 has not been fully tested. Tested versions: 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0. If you encounter issues, please report them or downgrade to a tested version.
    self._check_openai_version()

tests/test_async_client.py::TestAsyncTrackedChatCompletions::test_create_with_tracking_success
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\async_client.py:79: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    timestamp=datetime.utcnow()

tests/test_async_client.py::TestAsyncTrackedCompletions::test_create_with_tracking_success
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\async_client.py:143: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    timestamp=datetime.utcnow()

tests/test_basic_functionality.py: 1 warning
tests/test_performance.py: 65 warnings
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\performance.py:88: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    created_at=datetime.utcnow(),

tests/test_basic_functionality.py: 1 warning
tests/test_performance.py: 70 warnings
  <string>:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).

tests/test_basic_functionality.py: 1 warning
tests/test_performance.py: 68 warnings
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\performance.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    self.last_accessed = datetime.utcnow()

tests/test_logging_config.py::TestStructuredFormatter::test_basic_log_formatting
tests/test_logging_config.py::TestStructuredFormatter::test_log_formatting_with_custom_fields
tests/test_logging_config.py::TestStructuredFormatter::test_log_formatting_with_extra_fields
tests/test_logging_config.py::TestStructuredFormatter::test_log_formatting_with_exception
tests/test_logging_config.py::TestLoggingConfig::test_file_logging
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\logging_config.py:23: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    'timestamp': datetime.utcnow().isoformat() + 'Z',

tests/test_performance.py::TestCacheEntry::test_cache_entry_creation
  C:\Users\User\product\cmdrdata-openai\tests\test_performance.py:27: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    created_at=datetime.utcnow(),

tests/test_performance.py::TestCacheEntry::test_cache_entry_is_expired
  C:\Users\User\product\cmdrdata-openai\tests\test_performance.py:40: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    created_at=datetime.utcnow()

tests/test_performance.py::TestCacheEntry::test_cache_entry_is_expired
  C:\Users\User\product\cmdrdata-openai\tests\test_performance.py:47: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    created_at=datetime.utcnow() - timedelta(minutes=10),

tests/test_performance.py: 10 warnings
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\performance.py:35: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    return datetime.utcnow() - self.created_at > self.ttl

tests/test_performance.py::TestCacheEntry::test_cache_entry_is_expired
  C:\Users\User\product\cmdrdata-openai\tests\test_performance.py:55: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    created_at=datetime.utcnow() - timedelta(minutes=2),

tests/test_performance.py::TestCacheEntry::test_cache_entry_touch
  C:\Users\User\product\cmdrdata-openai\tests\test_performance.py:64: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    created_at=datetime.utcnow()

tests/test_tracker.py::TestUsageTracker::test_sanitize_tracking_data
  C:\Users\User\product\cmdrdata-openai\tests\test_tracker.py:140: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    timestamp = datetime.utcnow()

tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_success_httpx
  C:\Users\User\product\cmdrdata-openai\tests\test_tracker.py:182: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    "timestamp": datetime.utcnow().isoformat(),

tests/test_tracker.py::TestUsageTracker::test_track_usage_validation_error
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\tracker.py:96: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    "timestamp": (timestamp or datetime.utcnow()).isoformat()

tests/test_tracker.py::TestUsageTracker::test_track_usage_async_success
tests/test_tracker.py::TestUsageTracker::test_track_usage_async_fallback
  C:\Users\User\product\cmdrdata-openai\cmdrdata_openai\tracker.py:167: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    "timestamp": (timestamp or datetime.utcnow()).isoformat()

.venv\Lib\site-packages\_pytest\cacheprovider.py:429
  C:\Users\User\product\cmdrdata-openai\.venv\Lib\site-packages\_pytest\cacheprovider.py:429: PytestCacheWarning: cache could not write path C:\Users\User\product\cmdrdata-openai\.pytest_cache\v\cache\lastfailed: [Errno 13] Permission denied: 'C:\\Users\\User\\product\\cmdrdata-openai\\.pytest_cache\\v\\cache\\lastfailed'
    config.cache.set("cache/lastfailed", self.lastfailed)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/test_logging_config.py::TestLoggingConfig::test_file_logging - P...
FAILED tests/test_logging_config.py::TestLoggingConfig::test_invalid_log_file_path
FAILED tests/test_logging_config.py::TestUtilityFunctions::test_default_logging_config_values
FAILED tests/test_proxy.py::TestTrackedProxy::test_getattr_nonexistent_attribute
FAILED tests/test_proxy.py::TestTrackedProxy::test_setattr_private_attribute
FAILED tests/test_tracker.py::TestUsageTracker::test_initialization_missing_api_key
FAILED tests/test_tracker.py::TestUsageTracker::test_initialization_invalid_api_key_format
FAILED tests/test_tracker.py::TestUsageTracker::test_initialization_missing_endpoint
FAILED tests/test_tracker.py::TestUsageTracker::test_initialization_invalid_endpoint
FAILED tests/test_tracker.py::TestUsageTracker::test_initialization_invalid_timeout
FAILED tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_success
FAILED tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_missing_customer_id
FAILED tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_invalid_tokens
FAILED tests/test_tracker.py::TestUsageTracker::test_validate_tracking_inputs_invalid_metadata
FAILED tests/test_tracker.py::TestUsageTracker::test_sanitize_tracking_data
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_success_httpx
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_success_requests
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_rate_limited
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_server_error
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_client_error
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_with_retry_network_error
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_success - At...
FAILED tests/test_tracker.py::TestUsageTracker::test_track_usage_validation_error
FAILED tests/test_tracker.py::TestUsageTracker::test_get_health_status - Attr...
FAILED tests/test_tracker.py::TestUsageTrackerIntegration::test_full_tracking_flow_success
FAILED tests/test_validation.py::TestAPIKeyManager::test_validate_url_invalid_scheme
FAILED tests/test_validation.py::TestAPIKeyManager::test_validate_url_malformed
FAILED tests/test_version_compat.py::test_openai_version_detection - Attribut...
FAILED tests/test_version_compat.py::test_unsupported_openai_version - Attrib...
FAILED tests/test_version_compat.py::test_missing_openai - AttributeError: <m...
FAILED tests/test_version_compat.py::test_version_warnings - AttributeError: ...
FAILED tests/test_version_compat.py::test_python_version_support - AttributeE...
FAILED tests/test_version_compat.py::test_compatibility_with_fallback_version
================ 33 failed, 260 passed, 235 warnings in 7.24s =================
